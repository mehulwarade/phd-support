#!/usr/bin/env perl
#
# Simple Perl-script to summarize jobs and energy on a time scale so that
# all relevant information is in "one spot"
#
# Input: two files:
#  - list of jobs (as generated by 'parseJobstate.pl')
#  - energy measurements per node (as generated by 'imputeEnergy.pl')
#
# NOTE: some copy-and-paste from a previous script :-(
# NOTE: now also includes information about the number of 'waiting' jobs
#        -> fixed so that 'waiting' jobs are only counted overall
# NOTE: the energy data is 'optional' as the rest of the script works without
# NOTE: added 'Utilization' data
# NOTE: added completed jobs, by job type
# NOTE: made the job types more generic
#
# Author: Jean-Guy Schneider <schneidr@acm.org>
# Date:   Mon  7 Mar 2022 16:43:38 AEDT
#
#########################################################################

use List::Util qw(min);
use List::Util qw(max);

$DEBUG = 0;

#########################################################################

# CONSTANTS - indices for the column numbers of the 'list of jobs' data
# NOTE: updated based on new 'starting time'...
$JOB            =  0;
$JOB_ID         =  1;
$DAGMAN_ID      =  2;
$NODE_IP        =  3;
$SUBMIT         =  4;
$EXECUTE        =  5;
$JOB_TERMINATED =  6;
$SUCCESS        =  7;
$PS_STARTED     =  8;
$PS_TERMINATED  =  9;
$PS_SUCCESS     = 10;
$WAIT_TIME      = 11;
$EXEC_TIME      = 12;
$PS_TIME        = 13;

# CONSTANTS - the job types of the workflow to analyze
$JOB_TYPE_1 = "frequency";
$JOB_TYPE_2 = "individuals";
$JOB_TYPE_3 = "individuals_merge";
$JOB_TYPE_4 = "mutation_overlap";
$JOB_TYPE_5 = "sifting";

# For 'future use'...
$JOB_TYPE_6 = "";
$JOB_TYPE_7 = "";
$JOB_TYPE_8 = "";
$JOB_TYPE_9 = "";

# The list of workflow jobs in an array (for easier processing)
# NOTE: this should somewhat go into a configuration file -> ToDo
# NOTE: we will prune 'empty' job types as part of the script
@JOB_TYPES_ALL = ($JOB_TYPE_1, $JOB_TYPE_2, $JOB_TYPE_3, $JOB_TYPE_4, $JOB_TYPE_5, $JOB_TYPE_6, $JOB_TYPE_7, $JOB_TYPE_8, $JOB_TYPE_9);

# CONSTANTS - indices for the column numbers of the 'energy' data
$E_TIMSTAMP     = 0;
$E_TIME         = 1;
$E_TOTAL_ENERGY = 2;
$E_NODE_1       = 3;
# NOTE: '$E_NODE_2 = E_NODE_1 + 1', 'E_NODE_3 = E_NODE_2 + 1' etc.

# CONSTANTS - to be 'computed' for the output
$WAITING_JOBS = "WaitingJobs";
$TOTAL_JOBS   = "TotalJobs";
$NODE_ACTIVE  = "NodeActive";
$NODE_NUMBER  = "Node ID";
$NODE_ADDRESS = "Node IP";
$ENERGY       = "Energy";
$TOTAL_ENERGY = "TotalEnergy";
$UTILIZATION  = "Utilization";

# CONSTANTS - for header row in the generated output
$TIME_STAMP   = "Timestamp";
$TIME         = "Time";
$ALL          = "All";
$ALL_NODE_ID  = -1;
$HOST_NODE_ID = -2;
$COMPLETE     = "comp_";

# CONSTANTS - number of cores available; maximum utilization
$NO_CORES    = 4;
$MAX_VALUE   = 1;

# CONSTANTS - various delimeteres
$DEL         = ",";
$SEP         = "_";

#########################################################################

# The list of collected Node IPs
my %NODE_IPs;

#########################################################################

# Subroutine to print debugging information (only if '$DEBUG' is not 0)
sub printDebugInfo() {
    my ($text, @REST) = @_;
    if ($DEBUG) {
	print $text;
    }
}

# Subroutine to get the '$index' value of a comma-separated list
sub getValue() {
    my ($index, $aRow) = @_;
    my @values = split($DEL, $aRow);
    return @values[$index];
}

# Subroutine to create a new job_id as a merge of other information
sub getNewJobID() {
    my ($node_ip, $type, $job_id) = @_;
    return "$node_ip$SEP$type$SEP$job_id";
}

# Subroutine to get the job type of what has been created by 'getNewJobID'
sub getJobType() {
    my ($job_id, @rest) = @_;
    my @job_split = split($SEP, $job_id);
    return $job_split[1];
}

# Subroutine to get the Node IP what has been created by 'getNewJobID'
sub getJobNodeIP() {
    my ($job_id, @rest) = @_;
    my @job_split = split($SEP, $job_id);
    return $job_split[0];
}

# Subroutine to test 'list' membership
sub isInList() {

    my ($element, @LIST) = @_;
    my $result = 0;

    for $val (@LIST) {
	if ($val eq $element) {
	    $result = 1;
	    break;
	}
    }
    
    return $result;
}

#########################################################################

# Step 0 - parse the command-line arguments. We need at least two input files...
if (@ARGV < 2) {
    die "Insufficient input files given...";
}

my $job_data = "";
my $energy_data = "";
($job_data, $energy_data) = @ARGV;

# --------------------------------------------------------------------- #

# Step 1 - we need to filter out 'empty' job types from '@JOB_TYPES_ALL'
@JOB_TYPES;
my $index = 0;
foreach $val (@JOB_TYPES_ALL) {
    if ($val) {
	@JOB_TYPES[$index] = $val;
	$index++;
    }
}

# DEBUG for job types...
if ($DEBUG) {
    foreach $val (@JOB_TYPES) {
	print $val . " ";
    }
    print "\n";
}

# --------------------------------------------------------------------- #

# Step 2 - Read the 'job data' in 'one go' and store montage jobs in
#          '@JOB_DATA' and other jobs in '@HOST_DATA'
#          Also determine various (important) times along the way.
my $line = 0;
my @JOB_DATA;

my $hline = 0;
my @HOST_DATA;

my $header = 1;

# lets also collect the maximum and minimum time stamps
$min_submit     = 100000000000;      # large number to begin with :-)
$min_exec       = 100000000000;      # large number to begin with :-)
$max_success    = 0;
$max_ps_success = 0;

# Open the 'job data' file and read its contents.
open (JDFH, '<', $job_data) or die $!;
while(<JDFH>) {

    # Remove trailing newline character(s)
    chomp($_);
    $_ =~ s/\r|\n//g;

    # We are not interested in the header row... there may be a more elegant way...
    if ($header) {
	$header = 0;

    # Process the rest of the job data input
    } else {

	# Filter out any 'jobs' we are not interested in.
	my $job_type = &getValue($JOB, $_);

	# We only record Montage jobs for the cluster nodes
	if (&isInList($job_type, @JOB_TYPES)) {
	    $JOB_DATA[$line] = $_;
	    $line++;

	    # Update the hash with the Node IPs for all Montage jobs
	    my $node_ip = &getValue($NODE_IP, $_);
	    $NODE_IPs{$node_ip} = 1;
	} else {
	    @HOST_DATA[$hline] = $_;
	    $hline++;
	}

	# Update the maximum and minimum time stamps
	# NOTE: a job 'waits' from 'SUBMIT' to 'EXECUTE' (not included)
	my $timestamp = &getValue($SUBMIT, $_);
	if ($timestamp && ($timestamp < $min_submit)) {
	    $min_submit = $timestamp
	}

	# NOTE: a job 'runs' from 'EXECUTE' to 'SUCCESS'
	$timestamp = &getValue($EXECUTE, $_);
	if ($timestamp && ($timestamp < $min_exec)) {
	    $min_exec = $timestamp
	}
	$timestamp = &getValue($SUCCESS, $_);
	if ($timestamp && ($timestamp > $max_success)) {
	    $max_success = $timestamp
	}
	$timestamp = &getValue($PS_SUCCESS, $_);
	if ($timestamp && ($timestamp > $max_ps_success)) {
	    $max_ps_success = $timestamp
	}
    }
}
close(JDFH);

# --------------------------------------------------------------------- #

# Step 3 - define the start and end times for the output
# NOTE: we may not have energy data for all this period...
my $START_TIME = min (($min_submit, $min_exec));
my $END_TIME   = max (($max_success, $max_ps_success));

# --------------------------------------------------------------------- #

# Step 4 - record when each job is waiting (in %WAITING), active (in @ACTIVE)
#          and completed (in %COMPLETE).
# NOTE: we should probably use a hash for all three instances... ToDo later
my @ACTIVE;
my %WAITING;
my %COMPLETE;

for $job_info (@JOB_DATA) {

    # Get information about the current job
    my @VALUES = split ($DEL, $job_info);
    
    my $job_type = $VALUES[$JOB];
    my $job_id   = $VALUES[$JOB_ID];
    my $submit   = $VALUES[$SUBMIT];
    my $start    = $VALUES[$EXECUTE];
    my $end      = $VALUES[$SUCCESS];
    my $node_ip  = $VALUES[$NODE_IP];

    # DEBUG
    # printf ("%s_%s : %d - %d\n", $job_type, $job_id, $start, $end);

    # Record the current job as 'wating' from 'submit' to 'start - 1'
    # NOTE: we do not record the specific job type waiting, just the number.
    #       we also do not count waiting jobs on a per-node basis as they
    #       are only dispatched to a specific node one the move to 'EXECUTE'
    for (my $time_stamp = $submit; $time_stamp < $start; $time_stamp++) {

	if ($WAITING{$time_stamp} > 0) {
	    $WAITING{$time_stamp}++;
	} else {
	    $WAITING{$time_stamp} = 1;
	}
    }

    # Create a new job identifier as a merge of other information...
    my $new_job_id = &getNewJobID ($node_ip, $job_type, $job_id);

    # Record this job as active from '$start' to '$end' (inclusive)
    for ($time = $start; $time <= $end; $time++) {

	# Record the 'synthetic' job identifier be be active at 'time'
	if ($ACTIVE[$time]) {
	    $ACTIVE[$time] .= $DEL . $new_job_id;
	} else {
	    $ACTIVE[$time] = $new_job_id;
	}
    }

    # Record the current job as 'complete' for any time after 'end'
    # NOTE: we record the specific job type as well.
    for (my $time_stamp = ($end+1) ; $time_stamp <= $END_TIME; $time_stamp++) {

	if ($COMPLETE{$node_ip}{$job_type}{$time_stamp} > 0) {
	    $COMPLETE{$node_ip}{$job_type}{$time_stamp}++;
	} else {
	    $COMPLETE{$node_ip}{$job_type}{$time_stamp} = 1;
	}
    }    
}

# --------------------------------------------------------------------- #

# Step 5 - read the energy data (if available)
my %ENERGY_DATA;
$header = 1;
my $energy_head;

# Open the 'energy data' file (if available) and read its contents.
# open (EDFH, '<', $energy_data) or die $!;
if (open (EDFH, '<', $energy_data)) {
    while(<EDFH>) {
	chop $_;

	# Parse the header row... and extract IP addresses
	# NOTE: if not all IP addresses execute jobs, then they do not appear
	#       in the first input file!
	if ($header) {
	    $energy_head = $_;
	    $header = 0;

	    # Iterate over all IP addresses we have energy data for...
	    my (@HDATA) = split ($DEL, $_);
	    for ($node_index = $E_NODE_1; $node_index < @HDATA; $node_index++) {    
		$NODE_IPs{$HDATA[$node_index]} = 1;
	    }

	    # Parse the remaining rows of energy data
	} else {

	    my $row = $_;
	    my @VALUES = split ($DEL, $row);
	    
	    my $e_timestamp  = @VALUES[$E_TIMSTAMP];
	    my $total_energy = @VALUES[$E_TOTAL_ENERGY];

	    # Iterate over the energy data of each node, add to energy data
	    my $total_energy = 0;
	    for ($index = $E_NODE_1; $index < @VALUES; $index++) {

		# Get the energy data for the node and increment total energy
		my $node_energy_data = $VALUES[$index];
		$total_energy += $node_energy_data;

		# What is 'index' node ip? We have this information in header
		my $node_ip = &getValue($index, $energy_head);

		# Update energy data for 'node_ip'
		$ENERGY_DATA{$e_timestamp}{$node_ip} = $node_energy_data;
	    }

	    # Update the total energy data for 'e_timestamp'
	    $ENERGY_DATA{$e_timestamp}{$TOTAL_ENERGY} = $total_energy;
	}
    }
    close(EDFH);
}

# --------------------------------------------------------------------- #

# Step 6 - order the collected Node IPs
# NOTE: the value stored under a particular Node IP represents its Node number
my $count = 1;
for $ip (sort keys %NODE_IPs) {
    $NODE_IPs{$ip} = $count;
    $count++;
}

# The maximum number of nodes availabe
my $MAX_NODES = $count - 1;

# --------------------------------------------------------------------- #

# Print the energy data (for testing)
if ($DEBUG > 0) {
    for ($ts = $min_exec - 1; $ts <= $max_success + 1; $ts++) {

	print $ts . $DEL . $ENERGY_DATA{$ts}{$TOTAL_ENERGY};
	for $node (sort keys %NODE_IPs) {
	    print $DEL . "$node : $ENERGY_DATA{$ts}{$node}";
	}
	print "\n";
    }
}

# Print the 'waiting' data...
if ($DEBUG > 0) {
    print "\nWaiting information... \n";
    for $ts (sort keys $WAITING{$ip}) {
	print $ts;
	print $DEL . $WAITING{$ip}{$ts} . "\n";
    }
    exit 0;
}

# --------------------------------------------------------------------- #

# Step 7 - print the summary information... by node number
# NOTE: it may be worth splitting this code up into smaller 'chunks' in the
#       future...
$head = $TIME_STAMP . $DEL . $TIME . $DEL . $NODE_ADDRESS . $DEL . $NODE_NUMBER;
$head .= $DEL . $WAITING_JOBS;
for $info ((@JOB_TYPES, $TOTAL_JOBS, $NODE_ACTIVE)) {
    $head .= $DEL . $info;
}
$head .= $DEL . $ENERGY;
$head .= $DEL . $UTILIZATION;
for $info ((@JOB_TYPES, $TOTAL_JOBS)) {
    $head .= $DEL . $COMPLETE . $info;
}
print $head . "\n";

# Print the active jobs at each time interval
my $rel_time = 0;
for ($timestamp = $START_TIME; $timestamp <= $END_TIME; $timestamp++) {

    my %JOBS;

    # Get the list of active jobs at '$timestamp'
    my @active_jobs = split($DEL, $ACTIVE[$timestamp]);

    # Add the total number of active jobs
    my $total = @active_jobs;
    $JOBS{$TOTAL_JOBS} = $total;
    
    # Iterate over the list of active jobs
    for $job (@active_jobs) {

	my $node_ip  = &getJobNodeIP($job);
	my $job_type = &getJobType($job);

	# Mark '$node_ip' as being 'active' at '$timestamp'
	$JOBS{$node_ip}{$NODE_ACTIVE} = 1;

	# Increment the relevant job type count for '$node_ip'
	if ($JOBS{$node_ip}{$job_type}) {
	    $JOBS{$node_ip}{$job_type} = $JOBS{$node_ip}{$job_type} + 1;
	} else {
	    $JOBS{$node_ip}{$job_type} = 1;
	}

	# Increment the total count and utilization for 'node_ip'
	if ($JOBS{$node_ip}{$TOTAL_JOBS}) {
	    $JOBS{$node_ip}{$TOTAL_JOBS} = $JOBS{$node_ip}{$TOTAL_JOBS} + 1;
	} else {
	    $JOBS{$node_ip}{$TOTAL_JOBS} = 1;
	}

	# The utilization for 'node_ip' is the total number of jobs divided
	# by the number of cores available.
	# NOTE: in some (rare) instances we have more then 'NO_CORE' jobs so
	# we have a maximum value of 1 for the utilization.
	$JOBS{$node_ip}{$UTILIZATION} = ($JOBS{$node_ip}{$TOTAL_JOBS} / (1.0 * $NO_CORES));
	if ($JOBS{$node_ip}{$UTILIZATION} > $MAX_VALUE) {
	    $JOBS{$node_ip}{$UTILIZATION} = $MAX_VALUE;
	}

	# Increment the relevant job type count across all nodes
	if ($JOBS{$ALL}{$job_type}) {
	    $JOBS{$ALL}{$job_type} = $JOBS{$ALL}{$job_type} + 1;
	} else {
	    $JOBS{$ALL}{$job_type} = 1;
	}

	# Increment the total job type count across all nodes
	if ($JOBS{$ALL}{$TOTAL_JOBS}) {
	    $JOBS{$ALL}{$TOTAL_JOBS} = $JOBS{$ALL}{$TOTAL_JOBS} + 1;
	} else {
	    $JOBS{$ALL}{$TOTAL_JOBS} = 1;
	}
    }

    # Insert information about waiting jobs from '%WAITING' to '%JOBS'
    # NOTE: $JOBS{$node_ip}{$WAITING_JOBS} = 0 for all nodes except the
    #       'overall' node as jobs are 'waiting' in a single queue.
    for $node_ip (keys %NODE_IPs) {
	$JOBS{$node_ip}{$WAITING_JOBS} = 0;
    }

    if ($WAITING{$timestamp}) {
	$JOBS{$ALL}{$WAITING_JOBS} = $WAITING{$timestamp};
    } else {
	$JOBS{$ALL}{$WAITING_JOBS} = 0;
    }
    
    # Compute the number of active nodes and utilization at '$timestamp'
    # NOTE: make sure we only add the 'real' nodes but not the 'total' node...
    my $activeNODES = 0;
    for $node_ip (sort keys %NODE_IPs) {
	if ($JOBS{$node_ip}{$NODE_ACTIVE}) {
	    $activeNODES++;
	}
    }
    $JOBS{$ALL}{$NODE_ACTIVE} = $activeNODES;

    # The overall utilization is defined as the ratio of the number of active
    # nodes vs. the total number of nodes available.
    $JOBS{$ALL}{$UTILIZATION} = ($activeNODES / (1.0 * $MAX_NODES));

    # Print the job type counts and energy data on a per node basis...
    for $node_ip (sort keys %NODE_IPs) {

	# Get the node's ID
	my $node_id = $NODE_IPs{$node_ip};

	# Print time and location information
	printf ("%d, %d, %s, %d", $timestamp, $rel_time, $node_ip, $node_id);

	# Print information about waiting jobs on a per node basis
	print $DEL . $JOBS{$node_ip}{$WAITING_JOBS};

	# Iterate over all active jobs
	for $job_type ((@JOB_TYPES, $TOTAL_JOBS, $NODE_ACTIVE)) {

	    print "$DEL ";
	    if ($JOBS{$node_ip}{$job_type}) {
		print $JOBS{$node_ip}{$job_type};
	    } else {
		print "0";
	    }
	}

	# Add the energy information to the output (where available)
	print $DEL;
	if ($ENERGY_DATA{$timestamp}{$node_ip}) {
	    print $ENERGY_DATA{$timestamp}{$node_ip};
	}

	# Print utilization
	if ($JOBS{$node_ip}{$UTILIZATION}) {
	    print $DEL . $JOBS{$node_ip}{$UTILIZATION};
	} else {
	    print $DEL . "0";
	}

	# Print completed jobs at 'timestamp'
	my $node_jobs_complete = 0;
	for $job_type (@JOB_TYPES) {

	    print "$DEL ";
	    if ($COMPLETE{$node_ip}{$job_type}{$timestamp}) {
		print $COMPLETE{$node_ip}{$job_type}{$timestamp};
		$node_jobs_complete += $COMPLETE{$node_ip}{$job_type}{$timestamp};
	    } else {
		print "0";
	    }
	}
	print $DEL . $node_jobs_complete;

	# 'Finish' the row
	print "\n";
    }

    # Print the job type counts and energy data across all nodes...
    printf ("%d, %d, %s, %d", $timestamp, $rel_time, $ALL, $ALL_NODE_ID);

    # Print information about waiting jobs overall
    print $DEL . $JOBS{$ALL}{$WAITING_JOBS};
    
    for $job_type ((@JOB_TYPES, $TOTAL_JOBS, $NODE_ACTIVE)) {

	print "$DEL ";
	if ($JOBS{$ALL}{$job_type}) {
	    print $JOBS{$ALL}{$job_type};
	} else {
	    print "0";
	}
    }

    # Add the energy information to the output (where available)
    print $DEL;
    if ($ENERGY_DATA{$timestamp}{$TOTAL_ENERGY}) {
	print $ENERGY_DATA{$timestamp}{$TOTAL_ENERGY};
    }

    # Print utilization
    print $DEL . $JOBS{$ALL}{$UTILIZATION};

    # Print completed jobs overall - need to compute the totals first
    my $overall_complete = 0;
    for $job_type (@JOB_TYPES) {

	my $job_type_complete = 0;
	for $node_ip (sort %NODE_IPs) {
	    
	    $job_type_complete += $COMPLETE{$node_ip}{$job_type}{$timestamp};
	}

	print $DEL . $job_type_complete;
	$overall_complete += $job_type_complete;
    }
    print $DEL . $overall_complete;

    # 'Finish' the row
    print "\n";
    
    # Increment 'rel_time'
    $rel_time++;
}

# EOS

#########################################################################
